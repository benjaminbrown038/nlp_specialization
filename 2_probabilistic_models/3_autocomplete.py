import numpy as np
import pandas as pd
import math
import random
import nltk
nltk.download()

import w3_unittest
nltk.data.path.append()

with open():
    data = f.read()

print()
print()
print()
print()
print()
display(data[0:300])
print()

print()
print()
display(data[])
print()

def split_to_sentences():
    return sentences

x = 
split_to_sentences()

w3_unittest.test_split_to_sentences()

def tokenize_sentences():
    return tokenized_sentences

sentences 
tokenize_sentences

w3_unittest.test_tokenize_sentences()

def get_tokenized_data():
    return tokenized_sentences

x = 
get_tokenized_data

w3_unittest.test_Get_tokenied_data()

tokenized_data
random.seed()
random.shuffle()

train_size
train_data
test_data

print()
print()
print()
print()
print()

def count_words():
    return word_counts

tokenized_sentences
count_words

w3_unittest.test_count_words()

def get_words_with_nplus_frequency():
    return closed_vocab

tokenized_sentences = 
tmp_closed_vocab
print()
print()

w3_unittest.test_get_Words_with_nplus_frequency()

def replace_oov_words_by_unk():
    return replaced_tokenized_sentences

tokenized_sentences
vocabulary
tmp_replaced_tokenized_sentences
print
print
print
print

w3_unittest.test_replace_oov_words_by_unk

def preprocess_data():
    return train_data_replaced, test_data_replaced,vocabulary

tmp_train
tmp_test
tmp_train_repl, t

print
print
print
print
[rint
 print
print
print

w3_unittest
minimum_freq
train_data_processed, test_data_processed, vocabulary

print
print
print
print
print
print
print
print
print


def count_n_grams()
    return n_grams

sentences 
print
print
print
print
print

w3_unittest.test_count_n_grams

def estimate_probability():
    return probability

w3_unittest.test_estimate_probability()

def estimate_probabilities():

    return probabilties

sentences
unique_words
unigram_counts
bigram_counts
estimate_probabilities

trigram_counts
estimate_probabilties

def make_count_matrix():
    return count_matrix

sentences = 
unique_words
bigram_conts
print
display

print()
trigram_counts
display()

def make_probability_matrix():
    return prob_matrix

sentences
unique_words
bigram_counts
print()
display

print()
trigram_counts
display()

def calculate_perplexity():

    return perplexity

sentences
unique_words
unigram_counts
bigram_counts
perplexity_train
print()
test_sentence
perplexity_test
print

w3_unittest.test_calculate_perplexity

def suggest_a_word():
    return suggestion, max_prob

sentences 
unique_words
unigram_counts
bigram_counts

previous_tokens
tmp_suggest1
print

print

tmp_starts_with
tmp_suggest2
print()

w3_unittest.test_suggest_a_word()

def get_suggestions()
  return suggestions

sentences
unique_words
unigram_counts
bigram_counts
trigram_counts
quadgram_counts
qintgram_counts

n_gram_counts_list
previous_tokens
tmp_suggest3

print
display

n_gram_counts_list = 
for n in range
    print
    n_model_counts
    n_gram_counts_list

previous_tokens
tmp_suggest4
print
display

previous_tokens
tmp_suggest5
print
display

previous_tokens
print
display

privous_tokens
tmp_suggest6

print
display

previous_tokens
tmp_suggest8
print
display


